{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitchemvaecondaea948e1ecad94c438e3e08e0329b0955",
   "display_name": "Python 3.6.10 64-bit ('chemvae': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, os, sys, pandas as pd, csv, copy\n",
    "from pathlib import Path\n",
    "\n",
    "root = '../data'\n",
    "data_info = np.array(pd.read_table(root +'/list_eval_partition.txt', header=1, delim_whitespace=True))[:,:]\n",
    "#  np.array(pd.read_table(root +'/train_data/label.txt', delim_whitespace=True))[:,:]\n",
    "\n",
    "df = pd.read_table(root +'/list_eval_partition.txt', header=1, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          image_name      item_id  \\\n0       img/WOMEN/Dresses/id_00000002/02_1_front.jpg  id_00000002   \n1        img/WOMEN/Dresses/id_00000002/02_2_side.jpg  id_00000002   \n2        img/WOMEN/Dresses/id_00000002/02_4_full.jpg  id_00000002   \n3  img/WOMEN/Dresses/id_00000002/02_7_additional.jpg  id_00000002   \n4        img/WOMEN/Skirts/id_00000003/02_1_front.jpg  id_00000003   \n\n  evaluation_status  \n0             train  \n1             train  \n2             train  \n3             train  \n4             train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>item_id</th>\n      <th>evaluation_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img/WOMEN/Dresses/id_00000002/02_1_front.jpg</td>\n      <td>id_00000002</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img/WOMEN/Dresses/id_00000002/02_2_side.jpg</td>\n      <td>id_00000002</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img/WOMEN/Dresses/id_00000002/02_4_full.jpg</td>\n      <td>id_00000002</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img/WOMEN/Dresses/id_00000002/02_7_additional.jpg</td>\n      <td>id_00000002</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img/WOMEN/Skirts/id_00000003/02_1_front.jpg</td>\n      <td>id_00000003</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_from_path(pathstring):\n",
    "    \"\"\"retrives file names from the folder and returns a pandas dataframe with\n",
    "    four columns: path, filesize, lat, long\n",
    "\n",
    "    Arguments:\n",
    "        pathstring {string} -- relative location of file\n",
    "\n",
    "    Returns:\n",
    "        [pandas dataframe] -- sorted by the filesize\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = []\n",
    "    for file in Path(pathstring).glob(\"**/*.jpg\"):\n",
    "        \n",
    "        if file.parts[-2] == \"gallery\" or file.parts[-2] == \"query\":\n",
    "            evaluation_status = file.parts[-2]\n",
    "        else:\n",
    "            evaluation_status = \"train\"\n",
    "\n",
    "        filenames.append((str(file), file.parts[2], evaluation_status))\n",
    "    \n",
    "    files_df = pd.DataFrame(list(filenames),\n",
    "                            columns=[\"image_name\", \"item_id\", \"evaluation_status\"])\n",
    "    \n",
    "    sorted_files = files_df.sort_values(\"item_id\")\n",
    "    result_df = sorted_files.reset_index(drop=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_files_from_path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, query, gallery = data_info[data_info[:,2]=='train'][:,:2], data_info[data_info[:,2]=='query'][:,:2], data_info[data_info[:,2]=='gallery'][:,:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_conv = {x:i for i,x in enumerate(np.unique(np.array([int(x.split('_')[-1]) for x in train[:,1]])))}\n",
    "\n",
    "# train[:,1] = np.array([lab_conv[int(x.split('_')[-1])] for x in train[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(pd.read_table(root +'/train_data/label.txt', delimiter=','))[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ys, train_im_paths = [], []\n",
    "for img_path, key in train:\n",
    "    train_im_paths.append(os.path.join(root, 'Img', img_path))\n",
    "    train_ys += [int(key)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.huawei import Huawei_Dataset\n",
    "from dataset.utils import make_transform\n",
    "from dataset import sampler\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import torch, math, time, argparse, os\n",
    "import random, dataset, utils, losses, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/media/stevel/files/computerVision/proxy_anchor_DIGIX/code'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'resnet18'\n",
    "os.chdir('../data/')\n",
    "data_root = os.getcwd()\n",
    "trn_dataset = Huawei_Dataset(\n",
    "            root = data_root,\n",
    "            mode = 'train',\n",
    "            transform = make_transform(\n",
    "                is_train = True, \n",
    "                is_inception = (model == 'bn_inception')\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Balanced Sampling\n"
    }
   ],
   "source": [
    "IPC = 3\n",
    "sz_batch = 150\n",
    "nb_workers = 4\n",
    "\n",
    "if IPC:\n",
    "    balanced_sampler = sampler.BalancedSampler(trn_dataset, batch_size=sz_batch, images_per_class = IPC)\n",
    "    batch_sampler = BatchSampler(balanced_sampler, batch_size = sz_batch, drop_last = True)\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        num_workers = nb_workers,\n",
    "        pin_memory = True,\n",
    "        batch_sampler = batch_sampler\n",
    "    )\n",
    "    print('Balanced Sampling')\n",
    "    \n",
    "else:\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size = sz_batch,\n",
    "        shuffle = True,\n",
    "        num_workers = nb_workers,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    print('Random Sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(dl_tr):\n",
    "#     print(i, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a61fbd0e6d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m dataloader = DataLoader(trn_dataset, batch_size=4,\n\u001b[1;32m      5\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                         batch_sampler = batch_sampler)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# auto_collation with custom batch_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 raise ValueError('batch_sampler option is mutually exclusive '\n\u001b[0m\u001b[1;32m    196\u001b[0m                                  \u001b[0;34m'with batch_size, shuffle, sampler, and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                                  'drop_last')\n",
      "\u001b[0;31mValueError\u001b[0m: batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last"
     ]
    }
   ],
   "source": [
    "balanced_sampler = sampler.BalancedSampler(trn_dataset, batch_size=sz_batch, images_per_class = IPC)\n",
    "batch_sampler = BatchSampler(balanced_sampler, batch_size = sz_batch, drop_last = True)\n",
    "\n",
    "dataloader = DataLoader(trn_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0,\n",
    "                        batch_sampler = batch_sampler)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, data in enumerate(dataloader):\n",
    "#     print(i, data)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "hymenoptera_dataset = datasets.ImageFolder(root='train_data/',\n",
    "                                           transform=data_transform)\n",
    "# dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,\n",
    "#                                              batch_size=4, shuffle=True,\n",
    "#                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(trn_dataset,\n",
    "                        batch_size=4, shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3094"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(dataset_loader))\n",
    "\n",
    "for batch_idx, (x, y) in pbar:         \n",
    "     pbar.set_description(\n",
    "            'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}